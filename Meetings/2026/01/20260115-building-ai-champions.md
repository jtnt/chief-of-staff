# Building AI Champions in 2026 - Section Webinar

**Date:** January 15, 2026
**Time:** 3:00 PM - 4:00 PM EST
**Duration:** 53 minutes
**Type:** Webinar (Solo Attendance)
**Host:** Section
**Participants:** Lauren (moderator), Oya (Manulife AI Enablement Lead), Maxwell (co-host)

**Processed:** 2026-01-22 12:33 PM EST

---

## One-Line Summary

Manulife's AI Enablement Lead shares their framework for building and scaling an AI Champions program - starting with executive sponsorship, focusing on two clear goals (literacy + tool adoption), and providing white-glove support to a small core group of high-performing champions who cascade knowledge through their organizations.

---

## Key Takeaways

### Design Principles for Champions Programs

1. **Cultural fit is paramount** - Study what's worked in your organization before. Champions programs must mirror how successful change actually happens in your culture (top-down vs. bottom-up).

2. **Start small, iterate, expand** - Manulife launched MVP1 with a deliberately small core group, focused on pockets of high readiness and strong executive endorsement. They plan to expand in phases (MVP2, MVP3).

3. **Three critical success factors:**
   - Very clear purpose and objectives
   - Measurable outcomes from day one
   - Strong support infrastructure

4. **Less is more** - Don't overwhelm champions upfront. Spread cognitive load over time. They trimmed their initial scope multiple times based on leader feedback.

### Selection Criteria for Champions

Manulife used three filters for lead champions:
1. **Influence** - "The suns that sunflowers follow" - people others naturally go to with questions
2. **Performance** - High performers identified through data/systems
3. **Leadership endorsement** - Leaders confirmed these people were passionate, experienced, and already engaged with AI journey

For informal champions: Anyone can self-identify, no formal selection process.

### Goals and Measurement

**MVP1 had TWO goals only:**
1. **Raise AI literacy** - Provided "walking deck" for consistent messaging, tracked formal learning completion and confidence surveys
2. **Drive adoption of productivity tools** - Two tools available org-wide, measured actual usage/adoption rates

**Key insight:** Hands-on experiences (promptathons, demos) show direct correlation with adoption. When people prompt in the context of their role, adoption is sticky.

**Measurement approaches:**
- Formal learning program completion (leading indicator)
- Self-reported confidence surveys (feedback-rich culture)
- Tool usage/adoption data by department
- Role-specific adoption rates

### Onboarding and Support

**30-60-90 Day Journey:**
- 30 days: Role orientation, objectives, resources, custom learning pathway on internal platform
- 60-90 days: Experiential work - looking at adoption data, measuring literacy, creating roadmaps

**Resources provided:**
- Inventory of all learning resources
- Frameworks and playbooks
- Real-time data dashboard
- Walking deck (consistent AI messaging)
- Core messaging guide
- Access to AI/tech experts
- Connection to segment AI leads

**Ongoing support:**
- Monthly champion forum (team updates + collaborative sharing)
- Bi-weekly office hours (optional, thought-partnering)
- Live Teams channel for real-time questions

### Incentives and Recognition

**Non-monetary:**
- Resume value ("Lead AI Champion" in elite group)
- First access to new tools/licenses
- Access to experts and segment AI leads
- Badge/title for bragging rights

**Monetary/formal:**
- Formal feedback in mid-year reviews (leaders can reward as they see fit)
- Podium credits (appreciation program with company wall recognition)
- Innovation budget for experimentation
- In-person conference with recognition ceremonies planned

### Empowerment, Not Prescription

Champions receive:
- Clear outcomes to achieve (literacy, tool adoption)
- "Inventory" of available tactics (promptathons, demos, presentations, office hours, walking deck)
- Freedom to create own roadmap based on their area's context

Example: Finance champion organized org-wide promptathons series, hundreds participated. Another champion can replicate or adapt based on what they saw work.

**Forums spark imagination** - champions share what they're doing, others replicate or remix.

### Risk Management and Change Management

**Empathy training:** Partnership with global change enablement practice - helps champions handle resistance, address job loss fears, overcome objections.

**Narrative on responsible AI:** Strong communications partnership, access to risk/compliance experts. Manulife's narrative: AI enables growth and innovation, not workforce reduction.

**Consistency:** Walking deck ensures all champions deliver same core messages (reduces confusion, accelerates adoption).

### Getting Executive Buy-In

**Hands-on sessions with executives:**
- Asked for 20 minutes on existing leadership meeting agendas
- Had execs open laptops, log into tools, complete a challenge
- Result: "My team should be doing this! Can you come do this for my teams?"
- This approach cascaded through all levels, even the board

**Promptathons were born from this** - watching executive reactions and correlating with adoption data showed clear impact.

**Track leadership adoption too** - Daily active usage for leaders of teams is a leading indicator of team adoption.

### Top-Down vs. Bottom-Up Approaches

**Top-down (Manulife's approach):**
- Requires: Executive sponsorship, outcome-driven org, existing hardwired mechanisms (goals, performance mgmt, compensation)
- Advantage: Faster scaling, formal support, built into performance systems

**Bottom-up (for risk-averse orgs):**
- Find passionate "natural champions" already experimenting
- Bring them together monthly to share success stories
- Create badge/recognition without formal endorsement
- Use Teams channel for real-time community
- Start small, build movement, get quick wins
- Leadership buy-in comes after seeing results

**Questions to ask yourself:**
1. How do successful initiatives get started here? (Top-down or bottom-up?)
2. Do we have hardwired mechanisms (goal-setting, performance management, rewards) we can leverage?
3. Where is readiness highest right now?

### Use Case Evolution

**MVP1:** Focus on prompting, basic tool fluency, building the muscle
**MVP2 (expanding now):** Champions asked to understand underlying functionality of use cases to enable reuse vs. building from scratch

**Key insight:** Reuse > recreate. Faster, cheaper, proven success stories increase adoption likelihood.

### Lessons Learned and Pivots

**What went wrong:**
1. Initial champion count was too high - scaled down based on senior leader feedback. Landed in right place (manageable, well-supported).
2. 30-60-90 day onboarding still felt overwhelming - not everyone completed everything. "Less is more" principle.

**Top 3 design principles (Oya's advice):**
1. **Cultural fit** - Study what worked before in your org, get the secret sauce, incorporate it
2. **Clear purpose and objectives** - Give champions tangible goals to chase, North Star to align on
3. **Measurement + storytelling** - Measure value, tell the success story to maintain momentum (especially for side-of-desk work)

### Maintaining Momentum

**The challenge:** Side-of-desk roles get deprioritized over time as other things come up.

**The solution:** Continuously show tangible results and value to the organization. Momentum comes from evidence of impact.

**Support infrastructure:** Learning team, communications team, tech teams, communities of practice lead - "ton of people" providing support (not all full-time).

### Future Vision

**Could AI Champions become full-time roles?**
Oya: Yes, if scope expands beyond adoption to orchestrating workflows with agents, rethinking processes, driving innovation with AI. That requires intentionality and focus that could justify full-time.

"They're back to being a manager - but a manager of agents."

---

## How This Applies to Razzo

### Direct Parallels

**Sprint-First Model = Champions Program:**
- Both are about **human adoption at scale** through peer-to-peer enablement
- Both require **context** - champions explain AI in team's workflow, sprints embed AI in sales context
- Both emphasize **experiential learning** (promptathons = sprint exercises)
- Both track **adoption and behavior change**, not just awareness

**"Less is more" resonates deeply:**
- Manulife learned not to overwhelm champions despite 30-60-90 day journey
- Razzo sprints are already time-boxed, focused learning (good instinct validated)
- Don't try to teach everything - teach what drives adoption

**Measurement is critical:**
- Manulife tracks literacy (completion, confidence) + tool adoption (usage data)
- Razzo needs similar: sprint completion + tool adoption in sales workflow + behavior change (are reps actually using AI daily?)

### Key Insights for Razzo GTM

1. **The promptathon correlation**
   - Hands-on experience with tools in role-specific context = sticky adoption
   - Razzo sprints already do this (sales-specific exercises)
   - Validate with customers: Track adoption spike after sprint completion

2. **Two-tier structure works**
   - Core "lead champions" + informal champions who self-identify
   - Razzo equivalent: Sprint graduates become informal champions, subset become power users/advocates
   - Create pathway: Sprint participant → Champion → Case study / reference / co-marketing

3. **Empowerment over prescription**
   - Give outcomes + inventory of tactics + let them create roadmap
   - Razzo should provide sprint framework + modular exercises + let customers adapt to their context
   - "Co-creation" language resonates

4. **Executive sponsorship accelerator**
   - 20 minutes with execs, hands-on tool challenge = cascade effect
   - Razzo equivalent: Executive briefing session as part of enterprise package
   - Get VP Sales using AI, shows team it matters

5. **Bottom-up playbook for early customers**
   - Many won't have top-down AI buy-in yet
   - Position Razzo as: "Find your natural champions (reps already experimenting), run sprints with them, let success stories build momentum"
   - Badge/recognition angle: "AI-Ready Rep" certificate after sprint completion

6. **Support infrastructure matters**
   - Manulife has learning team, comms team, tech support, communities of practice
   - Razzo's version: Sprint facilitator support, alumni community, ongoing content/tactics, access to Razzo team for questions
   - White-glove support = competitive advantage (especially at enterprise level)

### Strategic Positioning

**Manulife's context validates Razzo's thesis:**
- Ranked #1 in life insurance, #5 globally for AI maturity
- **Still needed Champions program** to drive human adoption
- Having tools isn't enough - need structured enablement + community + support

**Razzo's advantage:**
- Sales-specific from day one (not generic AI literacy)
- Sprint format is already "less is more" (vs. 30-60-90 day journey)
- Built-in measurement (sprint completion, tool adoption, behavior change)

### Messaging Opportunities

**For Enterprise Prospects:**
"Leading AI organizations like Manulife build Champions programs to drive adoption at scale. Razzo sprints are your Champions program for sales - structured, role-specific, measurable, and designed for side-of-desk learning."

**For Bottom-Up Buyers:**
"Don't have executive buy-in yet? Start with your natural champions - the reps already experimenting with AI. Run a sprint, get quick wins, let success stories build momentum. That's how grassroots movements become org-wide initiatives."

**For Objection Handling (too much to learn):**
"Manulife learned: less is more. Don't overwhelm learners. Razzo sprints are time-boxed, focused, and contextual - just what you need to drive adoption, nothing more."

### Questions for Product/GTM

1. **Do we track adoption metrics post-sprint?** (Like Manulife tracks tool usage)
2. **Can we create alumni community/forum?** (Like Manulife's monthly champion forum)
3. **Should we offer "office hours" for sprint graduates?** (Optional thought-partnering)
4. **Can we certify graduates as "AI-Ready Sales Reps"?** (Badge/resume value)
5. **Do we have executive briefing offering?** (20-min hands-on for leadership)
6. **Can we formalize "sprint graduate → champion → advocate" pathway?**

### Content Ideas

1. **Case study format:** "[Company] built AI Champions program with Razzo sprints"
2. **Playbook:** "Building AI adoption from the ground up (even without executive buy-in)"
3. **Framework comparison:** "Champions Programs vs. Traditional Training (and why sprints win)"
4. **Measurement guide:** "How to track AI adoption in sales (beyond completion rates)"

---

## Follow-Ups

None (webinar format - no action items).

---

## Related Materials

- Raw transcript: `/Users/jtnt/Documents/Meeting Transcripts/20260115-building-ai-champions.md`
- Session transcript from Q&A covered: Champion selection, measurement, incentives, executive buy-in, bottom-up approaches, maintaining momentum
